
name: Integrated CI/CD Pipeline

on:
  push:
    branches: [ main, master, develop, stage, staging, FEAT/-Notifications-to-teams-and-slack, FEAT/-SonarQube_And_Trivy ]
  pull_request:
    branches: [ main, master, develop, stage, FEAT/-Notifications-to-teams-and-slack, FEAT/-SonarQube_And_Trivy ]
  workflow_dispatch:
    inputs:
      environment:
        description: 'Environment to deploy'
        required: true
        default: 'stage'
        type: choice
        options:
          - dev
          - stage
          - prod

permissions:
  contents: read
  security-events: write
  checks: write
  packages: write

env:
  JAVA_VERSION: '11'
  MAVEN_OPTS: '-Xmx3072m'
  REGISTRY: ghcr.io
  REPO_NAME_LOWER: ${{ github.event.repository.name }}
  IMAGE_PREFIX: ${{ github.repository_owner }}/${{ github.event.repository.name }}
  SLACK_WEBHOOK_URL: ${{ secrets.SLACK_WEBHOOK_URL }}
  ISSUE_TOKEN: ${{ secrets.ISSUE_TOKEN }}

concurrency:
  group: ${{ github.workflow }}-${{ github.ref }}
  cancel-in-progress: true

jobs:
  # ==================== JOB 1: SECURITY SCAN (Trivy) ====================
  security-scan:
    name: Security Scan (Trivy)
    runs-on: ubuntu-latest
    strategy:
      fail-fast: false
      matrix:
        service:
          - product-service
          - user-service
          - payment-service
          - order-service
          - shipping-service
          - favourite-service
          - api-gateway
          - cloud-config
          - service-discovery
          - proxy-client
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up JDK ${{ env.JAVA_VERSION }}
        uses: actions/setup-java@v4
        with:
          java-version: ${{ env.JAVA_VERSION }}
          distribution: 'temurin'

      - name: Cache Maven dependencies
        uses: actions/cache@v4
        with:
          path: ~/.m2
          key: ${{ runner.os }}-m2-${{ hashFiles('**/pom.xml') }}
          restore-keys: ${{ runner.os }}-m2-

      - name: Build JAR
        run: |
          cd ${{ matrix.service }}
          ../mvnw clean package -DskipTests

      - name: Set up JDK ${{ env.JAVA_VERSION }}
        uses: actions/setup-java@v4
        with:
          java-version: ${{ env.JAVA_VERSION }}
          distribution: 'temurin'
          cache: 'maven'

      - name: Run OWASP Dependency-Check
        continue-on-error: true
        run: |
          echo "Running OWASP Dependency-Check for ${{ matrix.service }}..."
          ./mvnw org.owasp:dependency-check-maven:check \
            -pl ${{ matrix.service }} \
            -am \
            -DfailBuildOnCVSS=0 \
            -DautoUpdate=true \
            -Dformat=HTML \
            -Dformat=JSON \
            -Dformat=XML || echo "OWASP scan completed with vulnerabilities"
        env:
          JAVA_OPTS: "-Xmx2048m"

      - name: Upload OWASP Reports
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: owasp-report-${{ matrix.service }}
          path: ${{ matrix.service }}/target/dependency-check-report.*
          retention-days: 30

      - name: Run Trivy vulnerability scanner
        uses: aquasecurity/trivy-action@master
        with:
          scan-type: 'fs'
          scan-ref: '${{ matrix.service }}/target'
          format: 'sarif'
          output: 'trivy-results-${{ matrix.service }}.sarif'
          severity: 'CRITICAL,HIGH'

      - name: Upload Trivy results to GitHub Security
        uses: github/codeql-action/upload-sarif@v4
        if: always()
        with:
          sarif_file: 'trivy-results-${{ matrix.service }}.sarif'

      - name: Scan Dockerfile
        uses: aquasecurity/trivy-action@master
        with:
          scan-type: 'fs'
          scan-ref: '${{ matrix.service }}/Dockerfile'
          format: 'table'
          exit-code: '1'
          severity: 'CRITICAL,HIGH'

  # ==================== JOB 2: UNIT & INTEGRATION TESTS ====================
  unit-integration-tests:
    name: Unit & Integration Tests
    runs-on: ubuntu-latest
    needs: [security-scan]
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up JDK ${{ env.JAVA_VERSION }}
        uses: actions/setup-java@v4
        with:
          java-version: ${{ env.JAVA_VERSION }}
          distribution: 'temurin'

      - name: Cache Maven dependencies
        uses: actions/cache@v4
        with:
          path: ~/.m2
          key: ${{ runner.os }}-m2-${{ hashFiles('**/pom.xml') }}
          restore-keys: ${{ runner.os }}-m2-

      - name: Run unit tests
        run: mvn -B test -Dtest="*Test" -DfailIfNoTests=false

      - name: Run integration tests
        run: mvn -B test -Dtest="*IntegrationTest" -DfailIfNoTests=false

      - name: Publish Test Results
        uses: EnricoMi/publish-unit-test-result-action@v2
        if: always()
        with:
          files: '**/target/surefire-reports/TEST-*.xml'
          check_name: 'Test Results'

      - name: Generate Test Report
        if: always()
        run: |
          mkdir -p test-results
          mvn surefire-report:report-only -Daggregate=true || true
          echo "Test reports generated"

      - name: Upload test results
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: test-results
          path: |
            **/target/surefire-reports/**
            **/target/site/surefire-report.html

  # ==================== JOB 3: BUILD DOCKER IMAGES ====================
  build-docker:
    name: Build Docker Images
    runs-on: ubuntu-latest
    needs: [unit-integration-tests]
    strategy:
      fail-fast: false
      matrix:
        service:
          - product-service
          - user-service
          - payment-service
          - order-service
          - shipping-service
          - favourite-service
          - api-gateway
          - cloud-config
          - service-discovery
          - proxy-client
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set repository name to lowercase
        id: repo-name
        run: |
          REPO_NAME_LOWER=$(echo "${{ github.event.repository.name }}" | tr '[:upper:]' '[:lower:]')
          echo "REPO_NAME_LOWER=$REPO_NAME_LOWER" >> $GITHUB_ENV
          echo "repo_name_lower=$REPO_NAME_LOWER" >> $GITHUB_OUTPUT

      - name: Set up JDK ${{ env.JAVA_VERSION }}
        uses: actions/setup-java@v4
        with:
          java-version: ${{ env.JAVA_VERSION }}
          distribution: 'temurin'
          cache: 'maven'

      - name: Build JAR files
        run: ./mvnw clean package -DskipTests -pl ${{ matrix.service }} -am

      - name: Verify JAR file exists
        run: |
          JAR_FILE="${{ matrix.service }}/target/${{ matrix.service }}-v0.1.0.jar"
          if [ ! -f "$JAR_FILE" ]; then
            echo "Error: JAR file not found at $JAR_FILE"
            echo "Contents of ${{ matrix.service }}/target/:"
            ls -la "${{ matrix.service }}/target/" || echo "Target directory does not exist"
            exit 1
          fi
          echo "JAR file found: $JAR_FILE"

      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v3

      - name: Log in to Container Registry
        uses: docker/login-action@v3
        with:
          registry: ${{ env.REGISTRY }}
          username: ${{ github.actor }}
          password: ${{ secrets.GITHUB_TOKEN }}
          logout: false

      - name: Extract metadata
        id: meta
        uses: docker/metadata-action@v5
        with:
          images: ${{ env.REGISTRY }}/${{ github.repository_owner }}/${{ steps.repo-name.outputs.repo_name_lower }}/${{ matrix.service }}
          tags: |
            type=ref,event=branch
            type=ref,event=pr
            type=semver,pattern={{version}}
            type=semver,pattern={{major}}.{{minor}}
            type=sha,prefix={{branch}}-

      - name: Build and push Docker image
        uses: docker/build-push-action@v5
        with:
          context: .
          file: ${{ matrix.service }}/Dockerfile
          push: ${{ github.event_name != 'pull_request' }}
          tags: ${{ steps.meta.outputs.tags }}
          labels: ${{ steps.meta.outputs.labels }}
          cache-from: type=gha
          cache-to: type=gha,mode=max
          platforms: linux/amd64
          build-args: |
            PROJECT_VERSION=0.1.0
          
      - name: List pushed image tags
        if: github.event_name != 'pull_request'
        run: |
          echo "Tags generated for ${{ matrix.service }}:"
          echo "${{ steps.meta.outputs.tags }}"
          echo ""
          echo "Full image name:"
          echo "${{ env.REGISTRY }}/${{ github.repository_owner }}/${{ steps.repo-name.outputs.repo_name_lower }}/${{ matrix.service }}"

      - name: Build image for local scan
        uses: docker/build-push-action@v5
        if: github.event_name != 'pull_request'
        with:
          context: .
          file: ${{ matrix.service }}/Dockerfile
          push: false
          load: true
          tags: ${{ matrix.service }}:local-scan
          cache-from: type=gha
          cache-to: type=gha,mode=max
          platforms: linux/amd64
          build-args: |
            PROJECT_VERSION=0.1.0

      - name: Scan image with Trivy
        uses: aquasecurity/trivy-action@master
        with:
          image-ref: ${{ matrix.service }}:local-scan
          format: 'sarif'
          output: 'trivy-image-${{ matrix.service }}.sarif'
          severity: 'CRITICAL,HIGH'
          exit-code: '0'
        if: github.event_name != 'pull_request'

      - name: Upload Trivy image scan results
        uses: github/codeql-action/upload-sarif@v4
        if: always() && github.event_name != 'pull_request'
        with:
          sarif_file: 'trivy-image-${{ matrix.service }}.sarif'

  # ==================== JOB 4: E2E TESTS ====================
  e2e-tests:
    name: E2E Tests (K8s + Newman)
    runs-on: ubuntu-latest
    needs: [build-docker]
    if: github.event_name != 'pull_request' || github.event.pull_request.head.repo.full_name == github.repository
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Install dependencies
        run: |
          sudo apt-get update
          sudo apt-get install -y jq curl

      - name: Install kubectl
        uses: azure/setup-kubectl@v4

      - name: Install kind
        uses: helm/kind-action@v1.10.0
        with:
          version: v0.23.0

      - name: Create kind cluster
        run: |
          kind create cluster --name e2e-test --wait 120s
          kubectl version --client

      - name: Set repository name to lowercase
        id: repo-name
        run: |
          REPO_NAME_LOWER=$(echo "${{ github.event.repository.name }}" | tr '[:upper:]' '[:lower:]')
          echo "REPO_NAME_LOWER=$REPO_NAME_LOWER" >> $GITHUB_ENV
          echo "repo_name_lower=$REPO_NAME_LOWER" >> $GITHUB_OUTPUT

      - name: Set up JDK ${{ env.JAVA_VERSION }}
        uses: actions/setup-java@v4
        with:
          java-version: ${{ env.JAVA_VERSION }}
          distribution: 'temurin'
          cache: 'maven'

      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v3

      - name: Build and load images into kind
        run: |
          set -e
          REPO_NAME_LOWER=$(echo "${{ github.event.repository.name }}" | tr '[:upper:]' '[:lower:]')
          TAG="${{ github.ref_name }}-${{ github.sha }}"
          
          echo "Building images locally and loading into kind..."
          
          for service in product-service user-service payment-service order-service shipping-service favourite-service api-gateway cloud-config service-discovery proxy-client; do
            echo "=== Building $service ==="
            
            # Construir JAR si no existe
            if [ ! -f "$service/target/${service}-v0.1.0.jar" ]; then
              echo "Building JAR for $service..."
              ./mvnw clean package -DskipTests -pl $service -am
            fi
            
            # Construir imagen Docker
            IMAGE_TAG="$REPO_NAME_LOWER/$service:$TAG"
            echo "Building Docker image: $IMAGE_TAG"
            docker buildx build \
              --load \
              --platform linux/amd64 \
              --build-arg PROJECT_VERSION=0.1.0 \
              -f $service/Dockerfile \
              -t "$IMAGE_TAG" \
              . || {
                echo "ERROR: Failed to build $service"
                exit 1
              }
            
            # Cargar imagen en kind
            echo "Loading $IMAGE_TAG into kind..."
            kind load docker-image "$IMAGE_TAG" --name e2e-test || {
              echo "ERROR: Failed to load $IMAGE_TAG into kind"
              exit 1
            }
            
            echo "âœ“ Successfully built and loaded $service"
          done
          
          echo "=== Verifying images in kind ==="
          docker exec e2e-test-control-plane crictl images | grep -E "(product-service|user-service|api-gateway)" || true

      - name: Update Kubernetes manifests with correct images
        run: |
          set -e
          REPO_NAME_LOWER=$(echo "${{ github.event.repository.name }}" | tr '[:upper:]' '[:lower:]')
          TAG="${{ github.ref_name }}-${{ github.sha }}"
          
          echo "Replacing images in Kubernetes manifests..."
          echo "Repository: $REPO_NAME_LOWER"
          echo "Tag: $TAG"
          
          # Reemplazar imÃ¡genes en los manifests
          # Usar el formato local que se cargÃ³ en kind (sin registry)
          for service in product-service user-service shipping-service payment-service order-service favourite-service api-gateway cloud-config service-discovery proxy-client; do
            OLD_IMAGE="selimhorri/${service}-ecommerce-boot:0.1.0"
            # Usar imagen local (sin registry) ya que estÃ¡ cargada en kind
            NEW_IMAGE="$REPO_NAME_LOWER/${service}:$TAG"
            echo "Replacing $OLD_IMAGE -> $NEW_IMAGE"
            
            # Reemplazar la imagen
            find k8s -name "*.yaml" -type f -not -path "*/security/*" -exec sed -i "s|${OLD_IMAGE}|${NEW_IMAGE}|g" {} \;
            
            # Agregar imagePullPolicy: Never para usar solo imÃ¡genes locales
            # Buscar la lÃ­nea con la imagen y agregar imagePullPolicy despuÃ©s
            find k8s -name "*.yaml" -type f -not -path "*/security/*" -exec sed -i "/image:.*${service}/a\          imagePullPolicy: Never" {} \;
          done
          
          echo "Verifying image replacements..."
          grep -A 1 "image:.*service" k8s/*.yaml | head -10 || true

      - name: Apply Kubernetes manifests in correct order
        run: |
          set -e
          # Crear namespace primero
          kubectl get ns ecommerce || kubectl create ns ecommerce
          
          echo "=== Step 1: Applying Service Discovery (Eureka) first ==="
          kubectl -n ecommerce apply -f k8s/service-discovery.yaml
          
          echo "=== Step 2: Waiting for Service Discovery (Eureka) to be ready ==="
          kubectl -n ecommerce wait --for=condition=available --timeout=180s deployment/service-discovery || {
            echo "âš ï¸  Service Discovery not ready, checking logs..."
            kubectl -n ecommerce logs -l app=service-discovery --tail=50 || true
          }
          
          # Verificar que Eureka estÃ¡ realmente listo (no solo el deployment)
          echo "Waiting for Eureka to finish initializing..."
          EUREKA_READY=false
          for i in $(seq 1 60); do
            POD_NAME=$(kubectl -n ecommerce get pod -l app=service-discovery -o jsonpath='{.items[0].metadata.name}' 2>/dev/null || echo "")
            if [ -n "$POD_NAME" ]; then
              if kubectl -n ecommerce logs "$POD_NAME" --tail=100 2>/dev/null | grep -qE "Finished initializing remote region registries|Started"; then
                echo "âœ“ Eureka is ready"
                EUREKA_READY=true
                break
              fi
            fi
            if [ $i -lt 60 ]; then
              sleep 3
            fi
          done
          if [ "$EUREKA_READY" = "false" ]; then
            echo "âš ï¸  Eureka may not be fully ready, but continuing..."
          fi
          
          echo "=== Step 3: Applying Cloud Config ==="
          kubectl -n ecommerce apply -f k8s/cloud-config.yaml
          
          echo "=== Step 4: Waiting for Config Server to be ready ==="
          kubectl -n ecommerce wait --for=condition=available --timeout=180s deployment/cloud-config || {
            echo "âš ï¸  Config Server not ready, checking logs..."
            kubectl -n ecommerce logs -l app=cloud-config --tail=50 || true
          }
          
          # Verificar que Config Server estÃ¡ realmente listo
          echo "Waiting for Config Server to finish initializing..."
          CONFIG_READY=false
          for i in $(seq 1 60); do
            POD_NAME=$(kubectl -n ecommerce get pod -l app=cloud-config -o jsonpath='{.items[0].metadata.name}' 2>/dev/null || echo "")
            if [ -n "$POD_NAME" ]; then
              if kubectl -n ecommerce logs "$POD_NAME" --tail=100 2>/dev/null | grep -qE "Tomcat started on port\\(s\\): 9296|Started"; then
                echo "âœ“ Config Server is ready"
                CONFIG_READY=true
                break
              fi
            fi
            if [ $i -lt 60 ]; then
              sleep 3
            fi
          done
          if [ "$CONFIG_READY" = "false" ]; then
            echo "âš ï¸  Config Server may not be fully ready, but continuing..."
          fi
          
          kubectl -n ecommerce apply -f k8s/order-service.yaml
          
          echo "=== Step 6: Waiting for Order Service to be ready ==="
          kubectl -n ecommerce wait --for=condition=available --timeout=240s deployment/order-service || {
            echo "âš ï¸  Order Service not ready, checking logs..."
            kubectl -n ecommerce logs -l app=order-service --tail=50 || true
          }
          
          # Verificar que Order Service estÃ¡ realmente listo
          echo "Waiting for Order Service to finish initializing..."
          ORDER_READY=false
          for i in $(seq 1 60); do
            POD_NAME=$(kubectl -n ecommerce get pod -l app=order-service -o jsonpath='{.items[0].metadata.name}' 2>/dev/null || echo "")
            if [ -n "$POD_NAME" ]; then
              if kubectl -n ecommerce logs "$POD_NAME" --tail=100 2>/dev/null | grep -qE "Tomcat started on port\\(s\\): 8300|Started"; then
                echo "âœ“ Order Service is ready"
                ORDER_READY=true
                break
              fi
            fi
            if [ $i -lt 60 ]; then
              sleep 3
            fi
          done
          if [ "$ORDER_READY" = "false" ]; then
            echo "âš ï¸  Order Service may not be fully ready, but continuing..."
          fi
          
          echo "=== Step 7: Applying Product Service ==="
          kubectl -n ecommerce apply -f k8s/product-service.yaml
          
          echo "=== Step 8: Waiting for Product Service to be ready ==="
          kubectl -n ecommerce wait --for=condition=available --timeout=240s deployment/product-service || {
            echo "âš ï¸  Product Service not ready, checking logs..."
            kubectl -n ecommerce logs -l app=product-service --tail=50 || true
          }
          
          # Verificar que Product Service estÃ¡ realmente listo
          echo "Waiting for Product Service to finish initializing..."
          PRODUCT_READY=false
          for i in $(seq 1 60); do
            POD_NAME=$(kubectl -n ecommerce get pod -l app=product-service -o jsonpath='{.items[0].metadata.name}' 2>/dev/null || echo "")
            if [ -n "$POD_NAME" ]; then
              if kubectl -n ecommerce logs "$POD_NAME" --tail=100 2>/dev/null | grep -qE "Tomcat started on port\\(s\\): 8500|Started"; then
                echo "âœ“ Product Service is ready"
                PRODUCT_READY=true
                break
              fi
            fi
            if [ $i -lt 60 ]; then
              sleep 3
            fi
          done
          if [ "$PRODUCT_READY" = "false" ]; then
            echo "âš ï¸  Product Service may not be fully ready, but continuing..."
          fi
          
          echo "=== Step 9: Applying Zipkin (after Order and Product services) ==="
          kubectl -n ecommerce apply -f k8s/zipkin.yaml || true
          
          echo "=== Step 10: Applying remaining services ==="
          kubectl -n ecommerce apply -f k8s/user-service.yaml
          kubectl -n ecommerce apply -f k8s/payment-service.yaml
          kubectl -n ecommerce apply -f k8s/shipping-service.yaml
          kubectl -n ecommerce apply -f k8s/favourite-service.yaml
          kubectl -n ecommerce apply -f k8s/api-gateway.yaml || true
          kubectl -n ecommerce apply -f k8s/proxy-client.yaml || true
          
          echo "âœ“ All manifests applied in correct order"

      - name: Check pod status and diagnose issues
        run: |
          set -e
          echo "=== Checking initial pod status ==="
          kubectl -n ecommerce get pods -o wide
          
          echo "=== Waiting for pods to be created (30s) ==="
          sleep 30
          
          echo "=== Checking pod status after sleep ==="
          kubectl -n ecommerce get pods -o wide
          
          echo "=== Checking events ==="
          kubectl -n ecommerce get events --sort-by='.lastTimestamp' | tail -20
          
          echo "=== Checking pods in detail ==="
          for pod in $(kubectl -n ecommerce get pods -o jsonpath='{.items[*].metadata.name}'); do
            echo "--- Pod: $pod ---"
            kubectl -n ecommerce describe pod "$pod" | grep -A 10 "Events:" || true
            kubectl -n ecommerce describe pod "$pod" | grep -A 5 "Status:" || true
            echo ""
          done

      - name: Wait for deployments Ready
        run: |
          set -e
          echo "=== Waiting for deployments to be available ==="
          echo "NOTE: It's normal for pods to take 1-3 minutes to become ready."
          echo "Spring Boot services need time to:"
          echo "  1. Start the application"
          echo "  2. Connect to Eureka (service-discovery)"
          echo "  3. Connect to Config Server (cloud-config)"
          echo "  4. Pass health checks"
          echo ""
          
          # FunciÃ³n para mostrar progreso
          show_progress() {
            echo "=== Current pod status ==="
            kubectl -n ecommerce get pods -o custom-columns=NAME:.metadata.name,STATUS:.status.phase,READY:.status.containerStatuses[0].ready,AGE:.metadata.creationTimestamp
            echo ""
          }
          
          # Esperar hasta 600s por todos los deployments
          echo "Waiting for deployments (max 10 minutes)..."
          TIMEOUT=600
          ELAPSED=0
          INTERVAL=15
          
          while [ $ELAPSED -lt $TIMEOUT ]; do
            if kubectl -n ecommerce wait --for=condition=available --timeout=${INTERVAL}s deployment --all 2>/dev/null; then
              echo "âœ“ All deployments are available!"
              break
            fi
            
            ELAPSED=$((ELAPSED + INTERVAL))
            echo "[${ELAPSED}s/${TIMEOUT}s] Still waiting for deployments..."
            show_progress
            sleep 5
          done
          
          if [ $ELAPSED -ge $TIMEOUT ]; then
            echo "=== Some deployments failed to become available ==="
            kubectl -n ecommerce get deployments -o wide
            kubectl -n ecommerce get pods -o wide
            kubectl -n ecommerce get events --sort-by='.lastTimestamp' | tail -30
            # Mostrar logs de pods que fallaron
            echo "=== Getting pods that failed ==="
            FAILED_PODS=$(kubectl -n ecommerce get pods -o json | jq -r '.items[] | select(.status.phase!="Running" and .status.phase!="Succeeded") | .metadata.name' 2>/dev/null || kubectl -n ecommerce get pods --field-selector=status.phase!=Running,status.phase!=Succeeded -o jsonpath='{.items[*].metadata.name}')
            
            if [ -n "$FAILED_PODS" ]; then
              for pod in $FAILED_PODS; do
                echo "=== Logs for failed pod: $pod ==="
                kubectl -n ecommerce logs "$pod" --tail=100 --all-containers=true || true
                echo ""
                echo "=== Describe pod: $pod ==="
                kubectl -n ecommerce describe pod "$pod" | tail -50 || true
                echo ""
              done
            else
              echo "No failed pods found, but deployments are not available"
              # Mostrar todos los pods para diagnÃ³stico
              echo "=== All pods status ==="
              kubectl -n ecommerce get pods -o wide
            fi
            exit 1
          fi
          
          echo ""
          echo "=== Waiting for pods to be ready (health checks passing) ==="
          echo "This may take additional time as services complete their startup..."
          
          ELAPSED=0
          while [ $ELAPSED -lt $TIMEOUT ]; do
            if kubectl -n ecommerce wait --for=condition=ready --timeout=${INTERVAL}s pod --all 2>/dev/null; then
              echo "âœ“ All pods are ready!"
              break
            fi
            
            ELAPSED=$((ELAPSED + INTERVAL))
            echo "[${ELAPSED}s/${TIMEOUT}s] Still waiting for pods to be ready..."
            show_progress
            
            # Mostrar quÃ© pods aÃºn no estÃ¡n listos
            if command -v jq &> /dev/null; then
              NOT_READY=$(kubectl -n ecommerce get pods -o json | jq -r '.items[] | select(.status.containerStatuses[0].ready != true) | .metadata.name' 2>/dev/null | tr '\n' ' ' || echo "")
            else
              # MÃ©todo alternativo sin jq
              NOT_READY=$(kubectl -n ecommerce get pods -o wide | grep -v "1/1.*Running" | grep -v "NAME" | awk '{print $1}' | tr '\n' ' ' || echo "")
            fi
            
            if [ -n "$NOT_READY" ]; then
              echo "Pods not ready yet: $NOT_READY"
              # Mostrar logs de los primeros 2 pods que no estÃ¡n listos
              for pod in $(echo "$NOT_READY" | tr ' ' '\n' | head -2); do
                echo "  Checking $pod..."
                kubectl -n ecommerce logs "$pod" --tail=20 2>/dev/null | tail -5 || echo "    (logs not available yet)"
                # Mostrar si el pod ha sido reiniciado
                RESTARTS=$(kubectl -n ecommerce get pod "$pod" -o jsonpath='{.status.containerStatuses[0].restartCount}' 2>/dev/null || echo "0")
                if [ "$RESTARTS" != "0" ]; then
                  echo "    âš ï¸  Pod has been restarted $RESTARTS times"
                  echo "    Previous container logs:"
                  kubectl -n ecommerce logs "$pod" --previous --tail=10 2>/dev/null | tail -3 || echo "      (previous logs not available)"
                fi
              done
            fi
            echo ""
            sleep 5
          done
          
          if [ $ELAPSED -ge $TIMEOUT ]; then
            echo "=== Some pods failed to become ready ==="
            kubectl -n ecommerce get pods -o wide
            kubectl -n ecommerce get events --sort-by='.lastTimestamp' | tail -30
            # Mostrar logs de pods que no estÃ¡n ready
            echo "=== Getting pods that are not ready ==="
            # Usar jq si estÃ¡ disponible, sino usar mÃ©todo alternativo
            if command -v jq &> /dev/null; then
              NOT_READY_PODS=$(kubectl -n ecommerce get pods -o json | jq -r '.items[] | select(.status.conditions[]? | select(.type=="Ready" and .status!="True")) | .metadata.name' 2>/dev/null || echo "")
            else
              # MÃ©todo alternativo sin jq
              NOT_READY_PODS=$(kubectl -n ecommerce get pods -o wide | grep -v "1/1.*Running" | grep -v "NAME" | awk '{print $1}' | grep -v "^$" || echo "")
            fi
            
            if [ -n "$NOT_READY_PODS" ]; then
              for pod in $NOT_READY_PODS; do
                echo "=== Logs for not-ready pod: $pod ==="
                kubectl -n ecommerce logs "$pod" --tail=100 --all-containers=true || true
                echo ""
                echo "=== Previous container logs (if restarted): $pod ==="
                kubectl -n ecommerce logs "$pod" --tail=50 --previous 2>/dev/null || echo "No previous logs available"
                echo ""
                echo "=== Describe pod: $pod ==="
                kubectl -n ecommerce describe pod "$pod" | tail -50 || true
                echo ""
              done
            else
              echo "No pods found that are not ready, but wait command failed"
              # Mostrar todos los pods para diagnÃ³stico
              echo "=== All pods status ==="
              kubectl -n ecommerce get pods -o wide
            fi
            exit 1
          fi
          
          echo ""
          echo "=== All pods are ready! ==="
          kubectl -n ecommerce get pods -o wide

      - name: Port-forward services to localhost
        run: |
          set -e
          # Obtiene el primer pod por etiqueta app
          pod_of() { kubectl -n "$1" get pod -l app="$2" -o jsonpath='{.items[0].metadata.name}'; }

          P_PRODUCT=$(pod_of ecommerce product-service)
          P_USER=$(pod_of ecommerce user-service)
          P_SHIP=$(pod_of ecommerce shipping-service)
          P_PAY=$(pod_of ecommerce payment-service)
          P_ORDER=$(pod_of ecommerce order-service)
          P_FAV=$(pod_of ecommerce favourite-service)

          echo "PF -> product-service: $P_PRODUCT, user-service: $P_USER, shipping: $P_SHIP, payment: $P_PAY, order: $P_ORDER, favourite: $P_FAV"

          # Lanzar port-forwards a pods en background
          nohup kubectl -n ecommerce port-forward pod/$P_PRODUCT 8500:8500 >/dev/null 2>&1 & echo $! > pf_product.pid
          nohup kubectl -n ecommerce port-forward pod/$P_USER 8700:8700 >/dev/null 2>&1 & echo $! > pf_user.pid
          nohup kubectl -n ecommerce port-forward pod/$P_SHIP 8600:8600 >/dev/null 2>&1 & echo $! > pf_shipping.pid
          nohup kubectl -n ecommerce port-forward pod/$P_PAY 8400:8400 >/dev/null 2>&1 & echo $! > pf_payment.pid
          nohup kubectl -n ecommerce port-forward pod/$P_ORDER 8300:8300 >/dev/null 2>&1 & echo $! > pf_order.pid
          nohup kubectl -n ecommerce port-forward pod/$P_FAV 8800:8800 >/dev/null 2>&1 & echo $! > pf_favourite.pid
          
          # Esperar un poco a que los port-forwards estÃ©n activos
          sleep 10

      - name: Warm-up and readiness checks (retry)
        run: |
          set -e
          retry() { for i in $(seq 1 24); do curl -fsS "$1" && echo "\nOK: $1" && return 0; echo "Retry $i: $1"; sleep 5; done; return 1; }

          if ! retry http://localhost:8500/product-service/api/products; then
            echo "DIAGNOSTICO: estado de product-service";
            kubectl -n ecommerce get svc product-service -o yaml || true
            kubectl -n ecommerce get endpoints product-service -o wide || true
            kubectl -n ecommerce get pod -l app=product-service -o wide || true
            P_PRODUCT=$(kubectl -n ecommerce get pod -l app=product-service -o jsonpath='{.items[0].metadata.name}' || true)
            [ -n "$P_PRODUCT" ] && kubectl -n ecommerce logs "$P_PRODUCT" --tail=200 || true
            exit 1
          fi

          if ! retry http://localhost:8700/user-service/api/users; then
            echo "DIAGNOSTICO: estado de user-service";
            kubectl -n ecommerce get pod -l app=user-service -o wide || true
            exit 1
          fi

          if ! retry http://localhost:8600/shipping-service/api/shippings; then
            echo "DIAGNOSTICO: estado de shipping-service";
            kubectl -n ecommerce get pod -l app=shipping-service -o wide || true
            exit 1
          fi

          if ! retry http://localhost:8400/payment-service/api/payments; then
            echo "DIAGNOSTICO: estado de payment-service";
            kubectl -n ecommerce get pod -l app=payment-service -o wide || true
            exit 1
          fi

          if ! retry http://localhost:8300/order-service/api/orders; then
            echo "DIAGNOSTICO: estado de order-service";
            kubectl -n ecommerce get pod -l app=order-service -o wide || true
            exit 1
          fi

          if ! retry http://localhost:8800/favourite-service/api/favourites; then
            echo "DIAGNOSTICO: estado de favourite-service";
            kubectl -n ecommerce get pod -l app=favourite-service -o wide || true
            exit 1
          fi

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '20'

      - name: Install Newman
        run: npm install -g newman

      - name: Run E2E tests
        run: |
          newman run tests/postman/ecommerce-e2e.postman_collection.json \
            --reporters cli,junit \
            --reporter-junit-export newman-results.xml

      - name: Upload E2E results
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: e2e-results
          path: newman-results.xml

      - name: Cleanup port-forwards
        if: always()
        run: |
          for pidfile in pf_*.pid; do
            if [ -f "$pidfile" ]; then
              kill $(cat "$pidfile") 2>/dev/null || true
              rm -f "$pidfile"
            fi
          done
          pkill -f "kubectl.*port-forward" || true

      - name: Cleanup
        if: always()
        run: kind delete cluster --name e2e-test || true

  # ==================== JOB 5: DEPLOY TO STAGE (with approval) ====================
  deploy-stage:
    name: Deploy to Stage Environment
    runs-on: ubuntu-latest
    needs: [e2e-tests, build-docker]
    environment:
      name: stage
      url: https://stage.ecommerce.example.com
    if: github.ref == 'refs/heads/stage' || github.ref == 'refs/heads/staging' || (github.event_name == 'workflow_dispatch' && github.event.inputs.environment == 'stage')
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Deploy to Kubernetes (Stage)
        run: |
          echo "Deploying to stage environment..."
          # kubectl apply -k k8s -n stage

      - name: Health check
        run: |
          echo "Performing health checks..."

  # ==================== JOB 6: DEPLOY TO PROD (with approval) ====================
  deploy-prod:
    name: Deploy to Production Environment
    runs-on: ubuntu-latest
    needs: [deploy-stage]
    environment:
      name: production
      url: https://ecommerce.example.com
    if: github.ref == 'refs/heads/main' || github.ref == 'refs/heads/master' || (github.event_name == 'workflow_dispatch' && github.event.inputs.environment == 'prod')
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Deploy to Kubernetes (Production)
        run: |
          echo "Deploying to production environment..."
          # kubectl apply -k k8s -n production

      - name: Health check
        run: |
          echo "Performing health checks..."

  # ==================== JOB 7: NOTIFICATIONS ====================
  notify:
    name: Send Notifications
    runs-on: ubuntu-latest
    needs: [security-scan, unit-integration-tests, build-docker, e2e-tests, deploy-stage, deploy-prod]
    if: always()
    steps:
      - name: Determine status
        id: status
        run: |
          if [ "${{ needs.security-scan.result }}" == "failure" ] || \
             [ "${{ needs.unit-integration-tests.result }}" == "failure" ] || \
             [ "${{ needs.build-docker.result }}" == "failure" ] || \
             [ "${{ needs.e2e-tests.result }}" == "failure" ]; then
            echo "status=failure" >> $GITHUB_OUTPUT
            echo "message=Pipeline failed. Check the logs for details." >> $GITHUB_OUTPUT
          else
            echo "status=success" >> $GITHUB_OUTPUT
            echo "message=Pipeline completed successfully!" >> $GITHUB_OUTPUT
          fi

      - name: Send Slack Notification (via webhook)
        if: always() && env.SLACK_WEBHOOK_URL != ''
        env:
          SLACK_WEBHOOK_URL: ${{ env.SLACK_WEBHOOK_URL }}
        run: |
          cat << 'EOF' > slack_payload.json
          {
            "text": "${{ steps.status.outputs.status == 'failure' && 'ðŸš¨ Pipeline Failed' || 'âœ… Pipeline Succeeded' }}",
            "blocks": [
              {
                "type": "section",
                "text": {
                  "type": "mrkdwn",
                  "text": "*${{ steps.status.outputs.status == 'failure' && 'ðŸš¨ Pipeline Failed' || 'âœ… Pipeline Succeeded' }}*\n\nRepository: ${{ github.repository }}\nBranch: ${{ github.ref_name }}\nCommit: <${{ github.server_url }}/${{ github.repository }}/commit/${{ github.sha }}|${{ github.sha }}>\nAuthor: ${{ github.actor }}\n\n${{ steps.status.outputs.message }}"
                }
              },
              {
                "type": "actions",
                "elements": [
                  {
                    "type": "button",
                    "text": {
                      "type": "plain_text",
                      "text": "View Run"
                    },
                    "url": "${{ github.server_url }}/${{ github.repository }}/actions/runs/${{ github.run_id }}"
                  }
                ]
              }
            ]
          }
          EOF

          echo "Calling Slack webhook: $SLACK_WEBHOOK_URL"
          curl -v -X POST \
            -H 'Content-type: application/json' \
            --data @slack_payload.json \
            "$SLACK_WEBHOOK_URL"

      - name: Create GitHub Issue on failure
        if: steps.status.outputs.status == 'failure' && env.ISSUE_TOKEN != ''
        uses: actions/github-script@v7
        env:
          ISSUE_TOKEN: ${{ env.ISSUE_TOKEN }}
        with:
          github-token: ${{ env.ISSUE_TOKEN }}
          script: |
            github.rest.issues.create({
              owner: context.repo.owner,
              repo: context.repo.repo,
              title: `ðŸš¨ Pipeline Failed: ${context.ref} - ${context.sha.substring(0, 7)}`,
              body: `Pipeline failed for commit ${context.sha}\n\n**Branch:** ${context.ref}\n**Author:** ${context.actor}\n**Workflow:** ${context.workflow}\n\n**Failed Jobs:**\n- Security Scan: ${{ needs.security-scan.result }}\n- Tests: ${{ needs.unit-integration-tests.result }}\n- Build: ${{ needs.build-docker.result }}\n- E2E: ${{ needs.e2e-tests.result }}\n\n[View Run](${context.serverUrl}/${context.repo.owner}/${context.repo.repo}/actions/runs/${context.runId})`,
              labels: ['bug', 'ci/cd']
            })
