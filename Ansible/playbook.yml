---
# =========================================================
# PLAY 1: Instalar y configurar Nginx en la máquina de CI
# =========================================================
- name: Instalar y configurar Nginx
  hosts: ci
  become: true
  tasks:
    - name: Actualizar cache de paquetes
      apt:
        update_cache: yes

    - name: Instalar Nginx
      apt:
        name: nginx
        state: present

    - name: Cambiar propietario de /var/www/html
      file:
        path: /var/www/html
        owner: "{{ ansible_user }}"
        group: "{{ ansible_user }}"
        recurse: yes

    - name: Asegurar directorios de sitios existen
      file:
        path: "{{ item }}"
        state: directory
        owner: root
        group: root
        mode: '0755'
      loop:
        - /etc/nginx/sites-available
        - /etc/nginx/sites-enabled

    - name: Instalar nginx.conf base (incluye sites-enabled)
      template:
        src: nginx-base.conf.j2
        dest: /etc/nginx/nginx.conf
        mode: '0644'
        validate: 'nginx -t -c %s'
      notify: validar y reiniciar nginx

    # --- Instalar el sitio de reverse proxy ---
    - name: Copiar configuración de reverse proxy a sites-available
      template:
        src: nginx.conf.j2
        dest: /etc/nginx/sites-available/reverse-proxy
        mode: '0644'
      notify: validar y reiniciar nginx

    - name: Deshabilitar sitio por defecto si existe
      file:
        path: /etc/nginx/sites-enabled/default
        state: absent
      notify: validar y reiniciar nginx

    - name: Habilitar reverse-proxy (sites-enabled)
      file:
        src: /etc/nginx/sites-available/reverse-proxy
        dest: /etc/nginx/sites-enabled/reverse-proxy
        state: link
        force: yes
      notify: validar y reiniciar nginx

    # --- Firewall UFW para la VM Nginx (opcional) ---
    - name: Instalar UFW
      apt:
        name: ufw
        state: present
      when: enable_ufw | default(false)

    - name: Establecer política por defecto (incoming deny, outgoing allow)
      ufw:
        direction: incoming
        policy: deny
      when: enable_ufw | default(false)

    - name: Establecer política por defecto (outgoing allow)
      ufw:
        direction: outgoing
        policy: allow
      when: enable_ufw | default(false)

    - name: Permitir OpenSSH (22)
      ufw:
        rule: allow
        name: OpenSSH
      when: enable_ufw | default(false)

    - name: Permitir HTTP (80)
      ufw:
        rule: allow
        port: '80'
        proto: tcp
      when: enable_ufw | default(false)

    - name: Permitir Locust (8089)
      ufw:
        rule: allow
        port: '8089'
        proto: tcp
      when: enable_ufw | default(false)

    # - name: Permitir HTTPS (443) [opcional]
    #   ufw:
    #     rule: allow
    #     port: '443'
    #     proto: tcp
    #   when: enable_ufw | default(false)

    - name: Habilitar UFW
      ufw:
        state: enabled
        logging: on
      when: enable_ufw | default(false)

  handlers:
    - name: Validar configuración de Nginx
      listen: "validar y reiniciar nginx"
      command: nginx -t
      register: nginx_test
      changed_when: false
      failed_when: nginx_test.rc != 0

    - name: Reiniciar/arrancar Nginx con configuración válida
      listen: "validar y reiniciar nginx"
      systemd:
        name: nginx
        state: restarted
        enabled: yes

# =========================================================
# PLAY 2: Instalar Docker + Docker Compose + Desplegar SonarQube/Locust + Trivy + Nginx
# =========================================================
- name: Instalar Docker y herramientas CI (SonarQube, Locust, Trivy) y Nginx
  hosts: ci
  vars:
    enable_swap: true
    swap_file_path: /swapfile
    swap_file_size_mb: 4096
    full_sonar_reset: true  # poner a true si quieres borrar TODO Sonar/Postgres en cada ejecución
    sonar_wait_strict: false
    sonar_wait_max_retries: 30
    sonar_wait_delay_seconds: 10
  tasks:
    # --- RESET COMPLETO OPCIONAL DE SONAR/POSTGRES + VOLUMENES ---
    - name: Reset completo de SonarQube y Postgres (opcional, destruye todos los datos)
      when: full_sonar_reset | default(false)
      block:
        - name: Detener y eliminar stack Sonar/Postgres + volúmenes
          become: false
          command: docker compose down -v --remove-orphans
          args:
            chdir: /home/{{ ansible_user }}/
          failed_when: false
          changed_when: true

        - name: Eliminar contenedores sueltos de SonarQube y Postgres
          become: false
          shell: |
            docker rm -f $(docker ps -aq --filter name=sonarqube) $(docker ps -aq --filter name=db) $(docker ps -aq --filter name=postgres) 2>/dev/null || true
          args:
            chdir: /home/{{ ansible_user }}/
          changed_when: false

        - name: Eliminar volúmenes de datos de SonarQube y Postgres
          become: false
          shell: |
            docker volume rm -f sonarqube_conf sonarqube_data sonarqube_extensions postgresql_data 2>/dev/null || true
          changed_when: false

    # --- TAREAS DE SISTEMA (con sudo) ---
    - name: Eliminar repo Trivy antiguo si existe (evitar error de Release)
      become: true
      file:
        path: /etc/apt/sources.list.d/trivy.list
        state: absent
      ignore_errors: true

    - name: Actualizar cache de paquetes
      become: true
      apt:
        update_cache: yes

    - name: Instalar dependencias para Docker
      become: true
      apt:
        name:
          - apt-transport-https
          - ca-certificates
          - curl
          - gnupg-agent
          - software-properties-common
        state: present

    - name: Agregar la clave GPG oficial de Docker
      become: true
      apt_key:
        url: https://download.docker.com/linux/ubuntu/gpg
        state: present

    - name: Agregar el repositorio de Docker
      become: true
      apt_repository:
        repo: deb [arch=amd64] https://download.docker.com/linux/ubuntu {{ ansible_lsb.codename }} stable
        state: present

    - name: Actualizar cache de paquetes después de agregar repo
      become: true
      apt:
        update_cache: yes

    - name: Instalar Docker Engine y plugins (incluye Compose v2)
      become: true
      apt:
        name:
          - docker-ce
          - docker-ce-cli
          - containerd.io
          - docker-buildx-plugin
          - docker-compose-plugin
        state: present

    - name: Asegurar que el servicio Docker esté iniciado y habilitado
      become: true
      systemd:
        name: docker
        state: started
        enabled: yes

    - name: Añadir el usuario actual al grupo docker
      become: true
      user:
        name: "{{ ansible_user }}"
        groups: docker
        append: yes

    - name: Eliminar binario antiguo de docker-compose si existe (Compose v1)
      become: true
      file:
        path: /usr/local/bin/docker-compose
        state: absent

    - name: Establecer vm.max_map_count en el kernel
      become: true
      sysctl:
        name: vm.max_map_count
        value: "262144"
        state: present
        reload: yes

    - name: Obtener estado del archivo de swap
      become: true
      stat:
        path: "{{ swap_file_path }}"
      register: swap_stat
      when: enable_swap | default(true)

    - name: Definir tamaño deseado de swap en bytes
      set_fact:
        swap_desired_bytes: "{{ (swap_file_size_mb | int) * 1024 * 1024 }}"
      when: enable_swap | default(true)

    - name: Redimensionar o crear swap si es necesario
      become: true
      block:
        - name: Deshabilitar swap si está activo (idempotente)
          command: swapoff {{ swap_file_path }}
          register: swapoff_out
          failed_when: false
          changed_when: swapoff_out.rc == 0

        - name: Crear/Redimensionar archivo de swap al tamaño deseado
          shell: |
            set -e
            fallocate -l {{ swap_file_size_mb }}M {{ swap_file_path }} || dd if=/dev/zero of={{ swap_file_path }} bs=1M count={{ swap_file_size_mb }}
            chmod 600 {{ swap_file_path }}
            mkswap {{ swap_file_path }}

        - name: Habilitar swap en runtime
          command: swapon {{ swap_file_path }}

      when: enable_swap | default(true)
        and (not swap_stat.stat.exists or (swap_stat.stat.exists and (swap_stat.stat.size | int) < (swap_desired_bytes | int)))

    - name: Asegurar entrada en /etc/fstab para swap
      become: true
      mount:
        name: none
        src: "{{ swap_file_path }}"
        fstype: swap
        opts: sw
        state: present
      when: enable_swap | default(true)

    - name: Ajustar swappiness (opcional)
      become: true
      sysctl:
        name: vm.swappiness
        value: "10"
        state: present
        reload: yes
      when: enable_swap | default(true)

    - name: Copiar archivo docker-compose.yml al servidor
      copy:
        src: docker-compose.yml
        dest: /home/{{ ansible_user }}/docker-compose.yml
        mode: '0644'

    - name: Copiar archivo nginx.conf para el Nginx del compose
      copy:
        src: nginx.conf
        dest: /home/{{ ansible_user }}/nginx.conf
        mode: '0644'

    - name: Comprobar si existe carpeta de Locust en el controlador
      become: false
      run_once: true
      stat:
        path: "{{ playbook_dir }}/../tests/locust"
      register: locust_dir
      failed_when: false
      changed_when: false

    - name: Copiar archivos de Locust (locustfile, etc.)
      copy:
        src: "{{ playbook_dir }}/../tests/locust/"
        dest: "/home/{{ ansible_user }}/locust/"
        mode: '0755'
      when: locust_dir.stat.exists | default(false)

    # Asegurar que SonarQube use el contexto /sonar creando/forzando sonar.properties en el volumen de conf
    - name: Establecer sonar.web.context en el volumen sonarqube_conf
      shell: |
        docker run --rm -v sonarqube_conf:/opt/sonarqube/conf busybox sh -c 'echo "sonar.web.context=/sonar" > /opt/sonarqube/conf/sonar.properties && chmod 644 /opt/sonarqube/conf/sonar.properties'
      changed_when: true

    # --- Limpieza de despliegues anteriores para evitar conflictos de nombre ---
    - name: Detener y eliminar stack previo (sin volúmenes)
      become: false
      command: docker compose down --remove-orphans
      args:
        chdir: /home/{{ ansible_user }}/
      failed_when: false
      changed_when: false
      when: not (reset_sonar_data | default(false))

    - name: Detener y eliminar stack previo + volúmenes (reset datos Sonar)
      become: false
      command: docker compose down -v --remove-orphans
      args:
        chdir: /home/{{ ansible_user }}/
      failed_when: false
      changed_when: false
      when: reset_sonar_data | default(false)

    - name: Eliminar contenedores antiguos que puedan causar conflicto (sonarqube)
      become: false
      shell: |
        docker rm -f $(docker ps -aq --filter name=sonarqube) || true
      args:
        chdir: /home/{{ ansible_user }}/
      changed_when: false

    - name: Eliminar contenedores antiguos que puedan causar conflicto (db/postgres)
      become: false
      shell: |
        docker rm -f $(docker ps -aq --filter name=db) $(docker ps -aq --filter name=postgres) || true
      args:
        chdir: /home/{{ ansible_user }}/
      changed_when: false

    - name: Descargar imágenes necesarias (docker compose pull)
      become: false
      command: docker compose pull
      args:
        chdir: /home/{{ ansible_user }}/

    - name: Levantar solo Postgres (db)
      become: false
      command: docker compose up -d --force-recreate db
      args:
        chdir: /home/{{ ansible_user }}/

    - name: Esperar a que Postgres esté healthy (hasta 10 minutos)
      become: false
      shell: docker inspect --format='{{"{{"}} .State.Health.Status {{"}}"}}' postgres
      register: pg_health
      retries: 120
      delay: 5
      until: pg_health.stdout.strip() == 'healthy'
      changed_when: false

    - name: Levantar SonarQube
      become: false
      command: docker compose up -d --force-recreate sonarqube
      args:
        chdir: /home/{{ ansible_user }}/

    - name: Esperar a que SonarQube quede operativo (docker health OR HTTP status=UP)
      become: false
      shell: |
        set -e
        if docker inspect --format='{{"{{"}} .State.Health.Status {{"}}"}}' sonarqube 2>/dev/null | grep -qx healthy; then
          exit 0
        fi
        curl -sS -L -H 'Accept: application/json' http://127.0.0.1:9000/sonar/api/system/status | grep -q '"status":"UP"' \
          || curl -sS -L -H 'Accept: application/json' http://127.0.0.1:9000/api/system/status | grep -q '"status":"UP"'
      args:
        chdir: "/home/{{ ansible_user }}/"
      register: sonar_ready
      retries: "{{ sonar_wait_max_retries }}"
      delay: "{{ sonar_wait_delay_seconds }}"
      until: sonar_ready.rc == 0
      changed_when: false
      ignore_errors: "{{ not (sonar_wait_strict | default(false) | bool) }}"

    - name: Advertir si SonarQube no estuvo listo a tiempo
      when:
        - sonar_ready is failed
      debug:
        msg: "SonarQube no llegó a estado healthy/UP dentro del playbook; revisar manualmente en http://CI_HOST:9000/sonar"

    # ===== Locust (master/worker) =====
    - name: Identificar contenedores Docker que publican el puerto 8089
      become: false
      command: docker ps -aq --filter publish=8089
      register: locust_conflicts
      failed_when: false
      changed_when: false

    - name: Detener y eliminar contenedores que ocupan 8089
      become: false
      when: locust_conflicts.stdout | length > 0
      loop: "{{ locust_conflicts.stdout_lines }}"
      command: docker rm -f {{ item }}
      changed_when: true

    - name: Liberar procesos que escuchen en el puerto 8089
      become: true
      shell: |
        fuser -k 8089/tcp || true
      changed_when: false

    - name: Verificar si el puerto 8089 está ocupado antes de levantar Locust
      become: true
      shell: ss -tulpn | grep ':8089'
      register: locust_port_check
      failed_when: false
      changed_when: false

    - name: Detener y eliminar contenedores Locust previos si el puerto está ocupado
      become: false
      when: locust_port_check.rc == 0
      shell: |
        docker compose stop locust-master locust-worker || true
        docker compose rm -f locust-master locust-worker || true
      args:
        chdir: /home/{{ ansible_user }}/
      changed_when: true

    - name: Levantar Locust (master y al menos 1 worker) si existe en docker-compose
      become: false
      shell: |
        if grep -q "locust-master" docker-compose.yml; then
          docker compose up -d --force-recreate locust-master locust-worker
        else
          echo "Locust no definido en docker-compose.yml, omitiendo despliegue de Locust"
        fi
      args:
        chdir: /home/{{ ansible_user }}/
      register: locust_up

    - name: Mostrar estado de contenedores de Locust si 8089 no respondió
      become: false
      when: (locust_up is defined and locust_up.rc != 0)
      shell: |
        echo "===== docker compose ps =====" && docker compose ps && \
        echo "===== logs locust-master =====" && docker logs --tail 50 locust-master || true && \
        echo "===== logs locust-worker =====" && docker logs --tail 50 locust-worker || true
      args:
        chdir: /home/{{ ansible_user }}/
      register: locust_debug
      changed_when: false
      failed_when: false

    - name: Levantar Nginx (compose)
      become: false
      command: docker compose up -d --force-recreate nginx
      args:
        chdir: /home/{{ ansible_user }}/

    # ===== Trivy CLI (opcional: instalar binario) =====
    - name: Instalar Trivy CLI desde script oficial (sin repos APT)
      become: false
      shell: |
        curl -sfL https://raw.githubusercontent.com/aquasecurity/trivy/main/contrib/install.sh \
          | sh -s -- -b /usr/local/bin
      args:
        creates: /usr/local/bin/trivy

    - name: Levantar Trivy (perfil tools) - opcional
      become: false
      command: docker compose --profile tools up -d trivy
      args:
        chdir: /home/{{ ansible_user }}/
      when: start_trivy_container | default(false)

# =========================================================
# PLAY 3: Despliegue en AKS desde el controlador
# =========================================================
- name: Preparar despliegues en AKS
  hosts: local
  gather_facts: false
  become: false
  vars:
    ansible_become: false
    aks_kubeconfig_path: "{{ lookup('env','AKS_KUBECONFIG') | default('~/.kube/aks-config', true) }}"
    aks_rg: "{{ lookup('env','AKS_RESOURCE_GROUP') }}"
    aks_name: "{{ lookup('env','AKS_CLUSTER_NAME') }}"
    aks_namespace: ecommerce
    manifests_root: "{{ playbook_dir }}/../k8s"
    helm_root: "{{ playbook_dir }}/../helm"
    helm_releases:
      - name: api-gateway
        chart: "{{ helm_root }}/api-gateway"
      - name: cloud-config
        chart: "{{ helm_root }}/cloud-config"
      - name: favourite-service
        chart: "{{ helm_root }}/favourite-service"
      - name: order-service
        chart: "{{ helm_root }}/order-service"
      - name: payment-service
        chart: "{{ helm_root }}/payment-service"
      - name: product-service
        chart: "{{ helm_root }}/product-service"
      - name: proxy-client
        chart: "{{ helm_root }}/proxy-client"
      - name: service-discovery
        chart: "{{ helm_root }}/service-discovery"
      - name: shipping-service
        chart: "{{ helm_root }}/shipping-service"
      - name: user-service
        chart: "{{ helm_root }}/user-service"
      - name: zipkin
        chart: "{{ helm_root }}/zipkin"
  tasks:
    - name: Resolver ruta absoluta del kubeconfig
      set_fact:
        aks_kubeconfig_resolved: "{{ aks_kubeconfig_path | expanduser }}"

    - name: Validar variables requeridas para AKS
      fail:
        msg: "Debes exportar AKS_RESOURCE_GROUP y AKS_CLUSTER_NAME antes de ejecutar este play."
      when: aks_rg | length == 0 or aks_name | length == 0

    - name: Verificar si ya existe el kubeconfig solicitado
      become: false
      stat:
        path: "{{ aks_kubeconfig_resolved }}"
      register: aks_kubeconfig_stat

    - name: Obtener credenciales de AKS vía Azure CLI
      become: false
      command: az aks get-credentials -g {{ aks_rg }} -n {{ aks_name }} --file {{ aks_kubeconfig_resolved }} --overwrite-existing
      changed_when: false
      when: aks_refresh_credentials | default(false) | bool or not aks_kubeconfig_stat.stat.exists

    - name: Exportar KUBECONFIG para las tareas siguientes
      set_fact:
        kubectl_env:
          KUBECONFIG: "{{ aks_kubeconfig_resolved }}"

    - name: Verificar conexión al cluster
      command: kubectl get nodes
      register: kubectl_nodes
      changed_when: false
      environment: "{{ kubectl_env }}"

    - name: Verificar si Helm está instalado
      command: helm version --short
      register: helm_check
      failed_when: false
      changed_when: false

    - name: Instalar Helm 3 si no está disponible
      become: true
      shell: curl -fsSL https://raw.githubusercontent.com/helm/helm/main/scripts/get-helm-3 | bash
      args:
        executable: /bin/bash
        creates: /usr/local/bin/helm
      when: helm_check.rc != 0

    - name: Asegurar namespace {{ aks_namespace }}
      command: kubectl create namespace {{ aks_namespace }} --dry-run=client -o yaml
      register: namespace_manifest
      changed_when: false
      environment: "{{ kubectl_env }}"

    - name: Aplicar namespace si no existe
      command: kubectl apply -f -
      args:
        stdin: "{{ namespace_manifest.stdout }}"
      when: namespace_manifest.stdout|length > 0
      environment: "{{ kubectl_env }}"

    - name: Aplicar manifests base desde {{ manifests_root }}
      command: kubectl apply -k "{{ manifests_root }}"
      changed_when: false
      environment: "{{ kubectl_env }}"

    - name: Detectar services legacy previos a despliegues Helm
      command: kubectl get service {{ item.name }} -n {{ aks_namespace }} -o jsonpath='{.metadata.labels.app\.kubernetes\.io/managed-by}'
      register: helm_service_owner
      failed_when: false
      changed_when: false
      loop: "{{ helm_releases }}"
      loop_control:
        label: "{{ item.name }}"
      environment: "{{ kubectl_env }}"

    - name: Eliminar services no gestionados por Helm
      command: kubectl delete service {{ item.item.name }} -n {{ aks_namespace }}
      loop: "{{ helm_service_owner.results }}"
      loop_control:
        label: "{{ item.item.name }}"
      when:
        - item.rc == 0
        - item.stdout.strip() != 'Helm'
      environment: "{{ kubectl_env }}"

    - name: Detectar deployments legacy previos a despliegues Helm
      command: kubectl get deployment {{ item.name }} -n {{ aks_namespace }} -o jsonpath='{.metadata.labels.app\.kubernetes\.io/managed-by}'
      register: helm_deploy_owner
      failed_when: false
      changed_when: false
      loop: "{{ helm_releases }}"
      loop_control:
        label: "{{ item.name }}"
      environment: "{{ kubectl_env }}"

    - name: Eliminar deployments no gestionados por Helm
      command: kubectl delete deployment {{ item.item.name }} -n {{ aks_namespace }}
      loop: "{{ helm_deploy_owner.results }}"
      loop_control:
        label: "{{ item.item.name }}"
      when:
        - item.rc == 0
        - item.stdout.strip() != 'Helm'
      environment: "{{ kubectl_env }}"

    - name: Desplegar charts en AKS
      command: helm upgrade --install {{ item.name }} "{{ item.chart }}" --namespace {{ aks_namespace }} --create-namespace
      loop: "{{ helm_releases }}"
      loop_control:
        label: "{{ item.name }}"
      changed_when: false
      environment: "{{ kubectl_env }}"

    - name: Mostrar estado final de pods
      command: kubectl get pods -n {{ aks_namespace }}
      changed_when: false
      environment: "{{ kubectl_env }}"
