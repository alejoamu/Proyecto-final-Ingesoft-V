---
# =========================================================
# PLAY 1: Instalar y configurar Nginx en la máquina de CI
# =========================================================
- name: Instalar y configurar Nginx
  hosts: ci
  become: true
  tasks:
    - name: Actualizar cache de paquetes
      apt:
        update_cache: yes

    - name: Instalar Nginx
      apt:
        name: nginx
        state: present

    - name: Cambiar propietario de /var/www/html
      file:
        path: /var/www/html
        owner: "{{ ansible_user }}"
        group: "{{ ansible_user }}"
        recurse: yes

    - name: Asegurar directorios de sitios existen
      file:
        path: "{{ item }}"
        state: directory
        owner: root
        group: root
        mode: '0755'
      loop:
        - /etc/nginx/sites-available
        - /etc/nginx/sites-enabled

    - name: Instalar nginx.conf base (incluye sites-enabled)
      template:
        src: nginx-base.conf.j2
        dest: /etc/nginx/nginx.conf
        mode: '0644'
        validate: 'nginx -t -c %s'
      notify: validar y reiniciar nginx

    # --- Instalar el sitio de reverse proxy ---
    - name: Copiar configuración de reverse proxy a sites-available
      template:
        src: nginx.conf.j2
        dest: /etc/nginx/sites-available/reverse-proxy
        mode: '0644'
      notify: validar y reiniciar nginx

    - name: Deshabilitar sitio por defecto si existe
      file:
        path: /etc/nginx/sites-enabled/default
        state: absent
      notify: validar y reiniciar nginx

    - name: Habilitar reverse-proxy (sites-enabled)
      file:
        src: /etc/nginx/sites-available/reverse-proxy
        dest: /etc/nginx/sites-enabled/reverse-proxy
        state: link
        force: yes
      notify: validar y reiniciar nginx

    # --- Firewall UFW para la VM Nginx (opcional) ---
    - name: Instalar UFW
      apt:
        name: ufw
        state: present
      when: enable_ufw | default(false)

    - name: Establecer política por defecto (incoming deny, outgoing allow)
      ufw:
        direction: incoming
        policy: deny
      when: enable_ufw | default(false)

    - name: Establecer política por defecto (outgoing allow)
      ufw:
        direction: outgoing
        policy: allow
      when: enable_ufw | default(false)

    - name: Permitir OpenSSH (22)
      ufw:
        rule: allow
        name: OpenSSH
      when: enable_ufw | default(false)

    - name: Permitir HTTP (80)
      ufw:
        rule: allow
        port: '80'
        proto: tcp
      when: enable_ufw | default(false)

    - name: Permitir Locust (8089)
      ufw:
        rule: allow
        port: '8089'
        proto: tcp
      when: enable_ufw | default(false)

    # - name: Permitir HTTPS (443) [opcional]
    #   ufw:
    #     rule: allow
    #     port: '443'
    #     proto: tcp
    #   when: enable_ufw | default(false)

    - name: Habilitar UFW
      ufw:
        state: enabled
        logging: on
      when: enable_ufw | default(false)

  handlers:
    - name: Validar configuración de Nginx
      listen: "validar y reiniciar nginx"
      command: nginx -t
      register: nginx_test
      changed_when: false
      failed_when: nginx_test.rc != 0

    - name: Reiniciar/arrancar Nginx con configuración válida
      listen: "validar y reiniciar nginx"
      systemd:
        name: nginx
        state: restarted
        enabled: yes

# =========================================================
# PLAY 2: Instalar Docker + Docker Compose + Desplegar SonarQube/Locust + Trivy + Nginx
# =========================================================
- name: Instalar Docker y herramientas CI (SonarQube, Locust, Trivy) y Nginx
  hosts: ci
  vars:
    enable_swap: true
    swap_file_path: /swapfile
    swap_file_size_mb: 4096
    full_sonar_reset: true  # poner a true si quieres borrar TODO Sonar/Postgres en cada ejecución
    sonar_wait_strict: false
    sonar_wait_max_retries: 30
    sonar_wait_delay_seconds: 10
  tasks:
    # --- RESET COMPLETO OPCIONAL DE SONAR/POSTGRES + VOLUMENES ---
    - name: Reset completo de SonarQube y Postgres (opcional, destruye todos los datos)
      when: full_sonar_reset | default(false)
      block:
        - name: Detener y eliminar stack Sonar/Postgres + volúmenes
          become: false
          command: docker compose down -v --remove-orphans
          args:
            chdir: /home/{{ ansible_user }}/
          failed_when: false
          changed_when: true

        - name: Eliminar contenedores sueltos de SonarQube y Postgres
          become: false
          shell: |
            docker rm -f $(docker ps -aq --filter name=sonarqube) $(docker ps -aq --filter name=db) $(docker ps -aq --filter name=postgres) 2>/dev/null || true
          args:
            chdir: /home/{{ ansible_user }}/
          changed_when: false

        - name: Eliminar volúmenes de datos de SonarQube y Postgres
          become: false
          shell: |
            docker volume rm -f sonarqube_conf sonarqube_data sonarqube_extensions postgresql_data 2>/dev/null || true
          changed_when: false

    # --- TAREAS DE SISTEMA (con sudo) ---
    - name: Eliminar repo Trivy antiguo si existe (evitar error de Release)
      become: true
      file:
        path: /etc/apt/sources.list.d/trivy.list
        state: absent
      ignore_errors: true

    - name: Actualizar cache de paquetes
      become: true
      apt:
        update_cache: yes

    - name: Instalar dependencias para Docker
      become: true
      apt:
        name:
          - apt-transport-https
          - ca-certificates
          - curl
          - gnupg-agent
          - software-properties-common
        state: present

    - name: Agregar la clave GPG oficial de Docker
      become: true
      apt_key:
        url: https://download.docker.com/linux/ubuntu/gpg
        state: present

    - name: Agregar el repositorio de Docker
      become: true
      apt_repository:
        repo: deb [arch=amd64] https://download.docker.com/linux/ubuntu {{ ansible_lsb.codename }} stable
        state: present

    - name: Actualizar cache de paquetes después de agregar repo
      become: true
      apt:
        update_cache: yes

    - name: Instalar Docker Engine y plugins (incluye Compose v2)
      become: true
      apt:
        name:
          - docker-ce
          - docker-ce-cli
          - containerd.io
          - docker-buildx-plugin
          - docker-compose-plugin
        state: present

    - name: Asegurar que el servicio Docker esté iniciado y habilitado
      become: true
      systemd:
        name: docker
        state: started
        enabled: yes

    - name: Añadir el usuario actual al grupo docker
      become: true
      user:
        name: "{{ ansible_user }}"
        groups: docker
        append: yes

    - name: Eliminar binario antiguo de docker-compose si existe (Compose v1)
      become: true
      file:
        path: /usr/local/bin/docker-compose
        state: absent

    - name: Establecer vm.max_map_count en el kernel
      become: true
      sysctl:
        name: vm.max_map_count
        value: "262144"
        state: present
        reload: yes

    - name: Obtener estado del archivo de swap
      become: true
      stat:
        path: "{{ swap_file_path }}"
      register: swap_stat
      when: enable_swap | default(true)

    - name: Definir tamaño deseado de swap en bytes
      set_fact:
        swap_desired_bytes: "{{ (swap_file_size_mb | int) * 1024 * 1024 }}"
      when: enable_swap | default(true)

    - name: Redimensionar o crear swap si es necesario
      become: true
      block:
        - name: Deshabilitar swap si está activo (idempotente)
          command: swapoff {{ swap_file_path }}
          register: swapoff_out
          failed_when: false
          changed_when: swapoff_out.rc == 0

        - name: Crear/Redimensionar archivo de swap al tamaño deseado
          shell: |
            set -e
            fallocate -l {{ swap_file_size_mb }}M {{ swap_file_path }} || dd if=/dev/zero of={{ swap_file_path }} bs=1M count={{ swap_file_size_mb }}
            chmod 600 {{ swap_file_path }}
            mkswap {{ swap_file_path }}

        - name: Habilitar swap en runtime
          command: swapon {{ swap_file_path }}

      when: enable_swap | default(true)
        and (not swap_stat.stat.exists or (swap_stat.stat.exists and (swap_stat.stat.size | int) < (swap_desired_bytes | int)))

    - name: Asegurar entrada en /etc/fstab para swap
      become: true
      mount:
        name: none
        src: "{{ swap_file_path }}"
        fstype: swap
        opts: sw
        state: present
      when: enable_swap | default(true)

    - name: Ajustar swappiness (opcional)
      become: true
      sysctl:
        name: vm.swappiness
        value: "10"
        state: present
        reload: yes
      when: enable_swap | default(true)

    - name: Copiar archivo docker-compose.yml al servidor
      copy:
        src: docker-compose.yml
        dest: /home/{{ ansible_user }}/docker-compose.yml
        mode: '0644'

    - name: Copiar archivo nginx.conf para el Nginx del compose
      copy:
        src: nginx.conf
        dest: /home/{{ ansible_user }}/nginx.conf
        mode: '0644'

    - name: Comprobar si existe carpeta de Locust en el controlador
      become: false
      run_once: true
      stat:
        path: "{{ playbook_dir }}/../tests/locust"
      register: locust_dir
      failed_when: false
      changed_when: false

    - name: Copiar archivos de Locust (locustfile, etc.)
      copy:
        src: "{{ playbook_dir }}/../tests/locust/"
        dest: "/home/{{ ansible_user }}/locust/"
        mode: '0755'
      when: locust_dir.stat.exists | default(false)

    # Asegurar que SonarQube use el contexto /sonar creando/forzando sonar.properties en el volumen de conf
    - name: Establecer sonar.web.context en el volumen sonarqube_conf
      shell: |
        docker run --rm -v sonarqube_conf:/opt/sonarqube/conf busybox sh -c 'echo "sonar.web.context=/sonar" > /opt/sonarqube/conf/sonar.properties && chmod 644 /opt/sonarqube/conf/sonar.properties'
      changed_when: true

    # --- Limpieza de despliegues anteriores para evitar conflictos de nombre ---
    - name: Detener y eliminar stack previo (sin volúmenes)
      become: false
      command: docker compose down --remove-orphans
      args:
        chdir: /home/{{ ansible_user }}/
      failed_when: false
      changed_when: false
      when: not (reset_sonar_data | default(false))

    - name: Detener y eliminar stack previo + volúmenes (reset datos Sonar)
      become: false
      command: docker compose down -v --remove-orphans
      args:
        chdir: /home/{{ ansible_user }}/
      failed_when: false
      changed_when: false
      when: reset_sonar_data | default(false)

    - name: Eliminar contenedores antiguos que puedan causar conflicto (sonarqube)
      become: false
      shell: |
        docker rm -f $(docker ps -aq --filter name=sonarqube) || true
      args:
        chdir: /home/{{ ansible_user }}/
      changed_when: false

    - name: Eliminar contenedores antiguos que puedan causar conflicto (db/postgres)
      become: false
      shell: |
        docker rm -f $(docker ps -aq --filter name=db) $(docker ps -aq --filter name=postgres) || true
      args:
        chdir: /home/{{ ansible_user }}/
      changed_when: false

    - name: Descargar imágenes necesarias (docker compose pull)
      become: false
      command: docker compose pull
      args:
        chdir: /home/{{ ansible_user }}/

    - name: Levantar solo Postgres (db)
      become: false
      command: docker compose up -d --force-recreate db
      args:
        chdir: /home/{{ ansible_user }}/

    - name: Esperar a que Postgres esté healthy (hasta 10 minutos)
      become: false
      shell: docker inspect --format='{{"{{"}} .State.Health.Status {{"}}"}}' postgres
      register: pg_health
      retries: 120
      delay: 5
      until: pg_health.stdout.strip() == 'healthy'
      changed_when: false

    - name: Levantar SonarQube
      become: false
      command: docker compose up -d --force-recreate sonarqube
      args:
        chdir: /home/{{ ansible_user }}/

    - name: Esperar a que SonarQube quede operativo (docker health OR HTTP status=UP)
      become: false
      shell: |
        set -e
        if docker inspect --format='{{"{{"}} .State.Health.Status {{"}}"}}' sonarqube 2>/dev/null | grep -qx healthy; then
          exit 0
        fi
        curl -sS -L -H 'Accept: application/json' http://127.0.0.1:9000/sonar/api/system/status | grep -q '"status":"UP"' \
          || curl -sS -L -H 'Accept: application/json' http://127.0.0.1:9000/api/system/status | grep -q '"status":"UP"'
      args:
        chdir: "/home/{{ ansible_user }}/"
      register: sonar_ready
      retries: "{{ sonar_wait_max_retries }}"
      delay: "{{ sonar_wait_delay_seconds }}"
      until: sonar_ready.rc == 0
      changed_when: false
      ignore_errors: "{{ not (sonar_wait_strict | default(false) | bool) }}"

    - name: Advertir si SonarQube no estuvo listo a tiempo
      when:
        - sonar_ready is failed
      debug:
        msg: "SonarQube no llegó a estado healthy/UP dentro del playbook; revisar manualmente en http://CI_HOST:9000/sonar"

    # ===== Locust (master/worker) =====
    - name: Levantar Locust (master y al menos 1 worker) si existe en docker-compose
      become: false
      shell: |
        if grep -q "locust-master" docker-compose.yml; then
          docker compose up -d --force-recreate locust-master locust-worker
        else
          echo "Locust no definido en docker-compose.yml, omitiendo despliegue de Locust"
        fi
      args:
        chdir: /home/{{ ansible_user }}/

    - name: Mostrar estado de contenedores de Locust si 8089 no respondió
      become: false
      when: locust_wait is failed or (locust_wait is defined and locust_wait.elapsed | default(0) >= 300)
      shell: |
        echo "===== docker compose ps =====" && docker compose ps && \
        echo "===== logs locust-master =====" && docker logs --tail 50 locust-master || true && \
        echo "===== logs locust-worker =====" && docker logs --tail 50 locust-worker || true
      args:
        chdir: /home/{{ ansible_user }}/
      register: locust_debug
      changed_when: false
      failed_when: false

    - name: Levantar Nginx (compose)
      become: false
      command: docker compose up -d --force-recreate nginx
      args:
        chdir: /home/{{ ansible_user }}/

    # ===== Trivy CLI (opcional: instalar binario) =====
    - name: Instalar Trivy CLI desde script oficial (sin repos APT)
      become: false
      shell: |
        curl -sfL https://raw.githubusercontent.com/aquasecurity/trivy/main/contrib/install.sh \
          | sh -s -- -b /usr/local/bin
      args:
        creates: /usr/local/bin/trivy

    - name: Levantar Trivy (perfil tools) - opcional
      become: false
      command: docker compose --profile tools up -d trivy
      args:
        chdir: /home/{{ ansible_user }}/
      when: start_trivy_container | default(false)

# =========================================================
# PLAY 3: Nodo K8s - K3s + microservicios (aplica manifests k3s/k8s)
# =========================================================
- name: K8s node - K3s + microservicios
  hosts: k8s
  become: true
  vars:
    k3s_channel: stable
    k3s_kubeconfig_path: /etc/rancher/k3s/k3s.yaml
    k3s_kubeconfig_local: /home/adminuser/.kube/config
    k3s_k8s_remote_dir: /home/adminuser/k8s-manifests
  tasks:
    - name: Update apt cache
      apt:
        update_cache: yes
        cache_valid_time: 3600

    - name: Ensure basic packages are present
      apt:
        name:
          - curl
          - ca-certificates
          - apt-transport-https
          - gnupg
          - lsb-release
          - git
        state: present

    - name: Ensure Docker service is running (Docker CE ya instalado en PLAY 2)
      systemd:
        name: docker
        state: started
        enabled: yes

    - name: Install k3s (single-node server)
      shell: |
        curl -sfL https://get.k3s.io | INSTALL_K3S_CHANNEL={{ k3s_channel }} sh -
      args:
        creates: /usr/local/bin/k3s

    - name: Ensure .kube directory exists for adminuser
      file:
        path: /home/adminuser/.kube
        state: directory
        owner: adminuser
        group: adminuser
        mode: "0755"

    - name: Copy k3s kubeconfig for adminuser
      copy:
        src: "{{ k3s_kubeconfig_path }}"
        dest: "{{ k3s_kubeconfig_local }}"
        remote_src: yes
        owner: adminuser
        group: adminuser
        mode: "0600"

    - name: Install kubectl
      get_url:
        url: https://dl.k8s.io/release/v1.30.3/bin/linux/amd64/kubectl
        dest: /usr/local/bin/kubectl
        mode: "0755"

    - name: Install Helm
      shell: |
        curl -fsSL https://raw.githubusercontent.com/helm/helm/main/scripts/get-helm-3 | bash
      args:
        creates: /usr/local/bin/helm

    - name: Create directory for k8s manifests on CI
      file:
        path: "{{ k3s_k8s_remote_dir }}"
        state: directory
        owner: adminuser
        group: adminuser
        mode: "0755"

    - name: Copy Kubernetes manifests (microservicios) to CI
      copy:
        src: k3s/k8s/
        dest: "{{ k3s_k8s_remote_dir }}/"
        owner: adminuser
        group: adminuser
        mode: "0644"

    - name: Comprobar si el namespace ecommerce ya existe
      become_user: adminuser
      shell: |
        set -e
        if kubectl get namespace ecommerce >/dev/null 2>&1; then
          echo "EXISTS"
        else
          echo "MISSING"
        fi
      args:
        chdir: "{{ k3s_k8s_remote_dir }}"
      register: ns_exists
      failed_when: false
      changed_when: false

    - name: Crear namespace ecommerce si está ausente
      become_user: adminuser
      shell: |
        kubectl create namespace ecommerce --validate=false || true
      args:
        chdir: "{{ k3s_k8s_remote_dir }}"
      when:
        - ns_exists.stdout is defined
        - ns_exists.stdout is search('MISSING')
      register: ns_create
      failed_when: false

    - name: Esperar a que el API de K3s responda antes de aplicar kustomize
      become_user: adminuser
      shell: |
        kubectl get nodes
      args:
        chdir: "{{ k3s_k8s_remote_dir }}"
      register: k3s_api_check
      retries: 30
      delay: 10
      until: k3s_api_check.rc == 0
      changed_when: false

    - name: Apply remaining manifests via kustomize (con reintentos para máquina limitada)
      become_user: adminuser
      shell: |
        kubectl apply -k .
      args:
        chdir: "{{ k3s_k8s_remote_dir }}"
      register: kustomize_apply
      retries: 3
      delay: 60
      until: kustomize_apply.rc == 0
      failed_when: kustomize_apply.rc not in [0]

